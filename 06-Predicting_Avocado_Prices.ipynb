{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This notebook took many ideas from the exploratory data analysis from the following Kaggle kernel:\n",
    "\n",
    "https://www.kaggle.com/hely333/explore-avocados-from-all-sides "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Avocado prices\n",
    "\n",
    "In this tutorial, we will analyze the avocado prices on different US cities and attempt to predict their future prices based on their type, production, and region.\n",
    "\n",
    "\n",
    "For that, we will use the [Avocado Prices dataset from Kaggle](https://www.kaggle.com/neuromusic/avocado-prices), compiled from the [Hass Avocado Board website](https://www.hassavocadoboard.com/retail/volume-and-price-data).\n",
    "\n",
    "The dataset is a table with the weekly 2015-2018 retail scan data for National retail volume (units) and price. The Average Price (of avocados) in the table reflects a per unit (per avocado) cost, even when multiple units (avocados) are sold in bags. The Product Lookup codes (**PLU**) in the table are only for Hass avocados. Other varieties of avocados (e.g. greenskins) are not included in this table.\n",
    "\n",
    "The tables columns are as follows:\n",
    "\n",
    "- **Date** : The date of the observation.\n",
    "- **AveragePrice** : the average price of a single avocado in USD.\n",
    "- **type** : conventional or organic.\n",
    "- **year** : the year of the observation (redundant information).\n",
    "- **region** : Region \n",
    "- **Total Volume** : Total number of avocados sold.\n",
    "- **4046** : Total number of avocados with PLU 4046 sold (small Hass).\n",
    "- **4225** : Total number of avocados with PLU 4225 sold (large Hass).\n",
    "- **4770** : Total number of avocados with PLU 4770 sold (extra large Hass).\n",
    "- **Total Bags** : total number of bags sold including all types.\n",
    "- **Small Bags** : total number of bags sold of small Hass.\n",
    "- **Large Bags** : total number of bags sold of large Hass.\n",
    "- **XLarge Bags** : total number of bags sold of extra large Hass.\t\n",
    "\n",
    "## Let's load the dataset first\n",
    "\n",
    "First, download the dataset zip file [from Kaggle's website](https://www.kaggle.com/neuromusic/avocado-prices/downloads/avocado.csv/1) and unzip it in the same folder where this notebook is.\n",
    "\n",
    "Then we can read the dataset with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "avocato_ds = pd.read_csv('avocado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see its contents using the [head method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html?highlight=head#pandas.DataFrame.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocato_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column and the second column contains an aritmetic progression staring from 0. These are equivalent to the row number.\n",
    "\n",
    "Now let's see the columns types and if the contains missing or non-null values using the [info method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html?highlight=info#pandas.DataFrame.info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocato_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset info**\n",
    "\n",
    "- The number of entries (weeks observed) is 18249 \n",
    "- All the columns contains **18249 non-null objects** (equal to the number of entries). Hence, we don't have missing values.\n",
    "- We are using 1.9 MB\n",
    "- The column \"Date\" type is object, which means a string in pandas. \n",
    "\n",
    "### The date column\n",
    "\n",
    "It is more convenient to convert the \"Date\" column to a datetime object which allows arithmetic operations between different times. For this we will use Panda's [to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html?highlight=to_datetime#pandas.to_datetime) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocato_ds['Date'] = pd.to_datetime(avocato_ds['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure that the rows are sorted by date using the [sort](https://pandas.pydata.org/pandas-docs/version/0.19/generated/pandas.DataFrame.sort.html) DataFrame method.\n",
    "This will become useful when we plot different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocato_ds.sort_values('Date',axis=0, ascending=True, inplace=True)\n",
    "# the axis keyword indicates along which direction to sort: the index (0) or columns (1).\n",
    "# ascending=True : sort in ascending order\n",
    "# the inplace=True keyword modifies the DataFrame in place (do not create a new object)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning \n",
    "\n",
    "Let's clean the dataset a little bit. The \"Unammed: 0\" and \"year\" column do not provide useful information. We can remove them using the [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)  method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocato_ds.drop(['Unnamed: 0', 'year'], axis=1,inplace=True)\n",
    "# the axis keyword indicates where to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "# the inplace=True keyword modifies the DataFrame in place (do not create a new object).\n",
    "avocato_ds.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis and data cleaning\n",
    "\n",
    "The exploratory data analysis (EDA) is an approach to analyze datasets to summarize their main characteristics. \n",
    "The objective of the EDA is to initial step in every data science project were you explore the characteristics of the data, find patterns or anomalies, test assumptions about the relationship between variables, etc.\n",
    "In a nutshell, the main goal is to maximize your knowledge of the dataset. \n",
    "\n",
    "Let's explore the contents of the columns containg strings columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocato_ds['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocato_ds['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we care the most when we buy avocados is their price. Let's start by plotting the temporal evolution of their prices.\n",
    "Let's start by plotting the average avocato prices for each type sold on the entire US (*TotalUS* region).\n",
    "We are going to select the rows in the [DataFrame by using bolean indexes](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#different-choices-for-indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import matplotlib first\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_US = avocato_ds['region']=='TotalUS'\n",
    "\n",
    "select_organic = avocato_ds['type']=='organic'\n",
    "\n",
    "select_conventional = avocato_ds['type']=='conventional'\n",
    "\n",
    "# The plot DataFrame's method return a matplotlib axes instance that can be reused in other plot() calls\n",
    "ax=avocato_ds[select_US&select_organic].plot(x='Date',y='AveragePrice',\n",
    "                                             label='organic', figsize=(12,5))\n",
    "\n",
    "avocato_ds[select_US&select_conventional].plot(x='Date',y='AveragePrice',\n",
    "                                               label='conventional',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There is something weird in the organic average price aorund Jun to Aug, 2015.**\n",
    "The prices drop to 1 USD and mantain that price over a few weeks.\n",
    "This is probably an error in the dataset.\n",
    "Luckly, we have the average price and total number of avocatos sold by region. We can compute our own TotalUS prices and compare it with the actual values in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's fix the TotalUS prices \n",
    "\n",
    "To obtain the Average Price over the entire US, we need to compute the total USD sold on each region,\n",
    "compute the total by region, and then divide by the total number of advocatos sold on the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the \"Total Sold\" column with the amount in USD sold each week (each row)\n",
    "avocato_ds['Total Sale']=avocato_ds['Total Volume']*avocato_ds['AveragePrice']\n",
    "\n",
    "# Let's select the main regions\n",
    "# The main regions are described in https://www.hassavocadoboard.com/retail/volume-and-price-data\n",
    "regions= ['Southeast', 'GreatLakes', 'Northeast', 'West',\n",
    "          'California',  'Plains',  'Midsouth', 'SouthCentral']\n",
    "\n",
    "# Reminder: ' | ' represents the 'or' logical operator\n",
    "select_major_regions = avocato_ds['region'] == regions[0]\n",
    "for region in regions[1:]:\n",
    "    select_major_regions = select_major_regions | (avocato_ds['region'] == region )\n",
    "\n",
    "# select_major_regions is a boolean Series, with a True value on the rows that \n",
    "# correspond any of the main region. False otherwise.\n",
    "organic_ds = avocato_ds[select_organic & select_major_regions]\n",
    "\n",
    "# Let's create a copy of the dataset with only the features we are interested in.\n",
    "organic_ds_short = organic_ds[['Date','Total Sale', 'Total Volume']]\n",
    "   \n",
    "# We take the total value for each week\n",
    "organic_ds_short=organic_ds_short.groupby('Date').sum()\n",
    "organic_ds_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the US Average price. \n",
    "us_average_price = organic_ds_short['Total Sale']/organic_ds_short['Total Volume']\n",
    "# us_average_price is a pandas Series, with the date as index\n",
    "print(type(us_average_price))\n",
    "\n",
    "us_average_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=avocato_ds[select_US&select_organic].plot(x='Date',y='AveragePrice',\n",
    "                                             label='organic (Original)',\n",
    "                                             legend=True, figsize=(12,5))\n",
    "us_average_price.plot(ax=ax,label='organic (New)',legend=True, color='r')\n",
    "ax.set_title('Total US - Average price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solved! Well, at least partially. \n",
    "\n",
    "We still need to __fix the values__ in our DataFrame **avocato_ds**.\n",
    "\n",
    "For that, in **avocato_ds**, we need to replace the \"AveragePrice\" values on all the rows where region=\"TotalUS\" and type='organic', by the values on **us_average_price** that we just compute. \n",
    "\n",
    "Let's review the data that we need to use:\n",
    "- **us_average_price** : Series index=Date , values=AveragePrice\n",
    "- **avocato_ds** : DataFrame, index=row number, we need to replace the values in the AveragePrice column.\n",
    "\n",
    "The series are using different indexes. This make simple assignments between DataFrame columns and series not possible.\n",
    "\n",
    "Let's create an auxiliary **us_average_price** Series that uses the row numbers as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_US = avocato_ds['region']=='TotalUS'\n",
    "select_organic = avocato_ds['type']=='organic'\n",
    "\n",
    "# Let's create a new DataFrame with the columns we need.\n",
    "aux_series = avocato_ds[select_US&select_organic][['Date','AveragePrice']]\n",
    "\n",
    "# Add the another column with the row number\n",
    "aux_series['row']=aux_series.index\n",
    "\n",
    "aux_series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use Date as index\n",
    "aux_series.set_index('Date',drop=False, inplace=True)\n",
    "aux_series.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **aux_series** and **us_average_price** uses the 'Date' as indexes. \n",
    "\n",
    "Let's check that the indexes are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_series.index.equals(us_average_price.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assing the values to AveragePrice\n",
    "aux_series['AveragePrice'] = us_average_price\n",
    "aux_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the indexes are not identical, not-a-number values are assignment on non overlapping indexes.\n",
    "\n",
    "Now, we are ready to update the old AveragePrice with the new computed ones using the DataFrame's [update](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.update.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index as row\n",
    "aux_series.set_index('row',drop=False, inplace=True)\n",
    "\n",
    "# Create a copy\n",
    "avocato_ds_fix=avocato_ds.copy()\n",
    "\n",
    "# Update the AveragePrice in the corresponding rows only.\n",
    "avocato_ds_fix['AveragePrice'].update(aux_series['AveragePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_US = avocato_ds_fix['region']=='TotalUS'\n",
    "\n",
    "select_organic = avocato_ds_fix['type']=='organic'\n",
    "\n",
    "select_conventional = avocato_ds_fix['type']=='conventional'\n",
    "\n",
    "# The plot DataFrame's method return a matplotlib axes instance that can be reused in other plot() calls\n",
    "ax=avocato_ds_fix[select_US&select_organic].plot(x='Date',y='AveragePrice',\n",
    "                                             label='organic', figsize=(12,5))\n",
    "\n",
    "avocato_ds_fix[select_US&select_conventional].plot(x='Date',y='AveragePrice',\n",
    "                                               label='conventional',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### 1) Plot the Average prices for different regions and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avocato_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Plot the Average prices over the US together with the Total Volume. Are they correlated? \n",
    "Use [plot.scatter method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Plot the Average prices over the US together with the Total Bags. Are they correlated? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting avocados prices\n",
    "\n",
    "Stay tunned for part two ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
